'use client'

import React, { useRef, useState, useMemo } from 'react'
import { strengths } from '../src/data/strengths'
import styles from './SpeakingSliderApp.module.css'

const studentResults = {
  í•˜í˜„ìš°: { open: ["åˆ›é€ åŠ›", "å¥½å¥‡å¿ƒ"], blind: ["åˆ¤æ–­åŠ›"], hidden: ["å‹‡æ•¢"], unknown: ["é¢†å¯¼åŠ›"] },
  ê¹€ë¯¼ì§€: { open: ["çƒ­æƒ…", "å–„è‰¯"], blind: ["æ´å¯ŸåŠ›"], hidden: ["åšæŒ"], unknown: ["ä¿¡ä»°"] },
  ë°•ì†Œì—°: { open: ["è¯šå®", "çˆ±å¿ƒ"], blind: ["æ‡‚åˆ«äºº"], hidden: ["è°¨æ…"], unknown: ["å¸Œæœ›"] },
} as const

const WINDOW_ORDER = ["open", "blind", "hidden", "unknown"] as const
const WINDOW_LABELS: Record<string, string> = {
  open: "ì—´ë¦° ì°½",
  blind: "ë³´ì´ì§€ ì•ŠëŠ” ì°½",
  hidden: "ìˆ¨ê¸´ ì°½",
  unknown: "ë¯¸ì§€ì˜ ì°½",
}

const IMAGE_BASE = 'https://cdn.jsdelivr.net/gh/hghdz/card-selector-app/images'

const SpeakingSliderApp = () => {
  const [selectedStudent, setSelectedStudent] = useState<keyof typeof studentResults>('í•˜í˜„ìš°')
  const [index, setIndex] = useState(0)
  const [isRecording, setIsRecording] = useState(false)
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null)
  const audioRef = useRef<HTMLAudioElement | null>(null)

  const result = studentResults[selectedStudent]

  const slides = useMemo(() => {
    const all: any[] = []
    for (const type of WINDOW_ORDER) {
      const hanziList = result[type] || []
      hanziList.forEach((hanzi: string) => {
        const data = strengths.find((s) => s.hanzi === hanzi)
        if (data) all.push({ ...data, windowType: type })
      })
    }
    return all
  }, [result])

  const current = slides[index]
  const highlight = (text: string, keyword: string) =>
    text.replace(new RegExp(keyword, 'g'), `<span style="color:red;font-weight:bold;">${keyword}</span>`)

  const sentence = {
    zh: (
      current.windowType === "blind"
        ? `æœ‹å‹è¯´${current.baseSentence}`
        : current.windowType === "hidden"
        ? `æˆ‘è§‰å¾—${current.baseSentence}`
        : current.windowType === "unknown"
        ? current.unknownSentence
        : current.baseSentence
    ),
    py: (
      current.windowType === "blind"
        ? `PÃ©ngyou shuÅ ${current.basePinyin}`
        : current.windowType === "hidden"
        ? `WÇ’ juÃ©de ${current.basePinyin}`
        : current.windowType === "unknown"
        ? current.unknownPinyin
        : current.basePinyin
    ),
    kr: (
      current.windowType === "blind"
        ? `ì¹œêµ¬ê°€ ë§í•˜ê¸¸ ${current.desc}`
        : current.windowType === "hidden"
        ? `ë‚´ê°€ ìƒê°í•˜ê¸°ì— ${current.desc}`
        : current.windowType === "unknown"
        ? current.unknownDesc
        : current.desc
    )
  }

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      const recorder = new MediaRecorder(stream)
      const chunks: BlobPart[] = []

      recorder.ondataavailable = (e) => chunks.push(e.data)
      recorder.onstop = () => {
        const blob = new Blob(chunks, { type: 'audio/webm' })
        const url = URL.createObjectURL(blob)
        if (audioRef.current) {
          audioRef.current.src = url
          audioRef.current.play()
        }
        setMediaRecorder(null)
      }

      recorder.start()
      setMediaRecorder(recorder)
      setIsRecording(true)
    } catch {
      alert("ğŸ™ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
    }
  }

  const stopRecording = () => {
    mediaRecorder?.stop()
    setIsRecording(false)
  }

  return (
    <div className={styles.wrapper}>
      <div className={styles.progressBar}>
        {[...Array(slides.length)].map((_, i) => (
          <div key={i} className={`${styles.progress} ${i <= index ? styles.active : ''}`} />
        ))}
      </div>

      <div className={styles.slider}>
        <button onClick={() => setIndex((i) => Math.max(0, i - 1))}>â—€</button>

        <div className={styles.imageBox}>
          {current && (
            <img
              key={current.hanzi}
              src={`${IMAGE_BASE}/${current.hanzi}.png`}
              alt={current.hanzi}
              className={styles.img}
            />
          )}
        </div>

        <button onClick={() => setIndex((i) => Math.min(slides.length - 1, i + 1))}>â–¶</button>
      </div>

      <div>
        <p dangerouslySetInnerHTML={{ __html: highlight(sentence.zh, current.hanzi) }} />
        <p dangerouslySetInnerHTML={{ __html: highlight(sentence.py, current.hanzi) }} />
        <p dangerouslySetInnerHTML={{ __html: highlight(sentence.kr, current.hanzi) }} />
      </div>

      <div className={styles.buttonGroup}>
        <button className={`${styles.button} ${styles.listen}`} onClick={() => {
          const utter = new SpeechSynthesisUtterance(sentence.zh)
          utter.lang = 'zh-CN'
          speechSynthesis.speak(utter)
        }}>ğŸ”Š ë“£ê¸°</button>

        <button className={`${styles.button} ${isRecording ? styles.stop : styles.record}`} onClick={() => (!mediaRecorder ? startRecording() : stopRecording())}>
          {isRecording ? 'â¹ ì¤‘ì§€' : 'ğŸ™ ë…¹ìŒ'}
        </button>

        <button className={`${styles.button} ${styles.play}`} onClick={() => { if (audioRef.current) audioRef.current.play() }}>â–¶ ì¬ìƒ</button>
      </div>

      <audio ref={audioRef} controls className={styles.audio} />
    </div>
  )
}

export default SpeakingSliderApp;
